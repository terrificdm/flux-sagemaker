{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1ad712-3a32-4e66-8d5a-6952b849cdc9",
   "metadata": {},
   "source": [
    "## FLUX.1-dev Lora finetune on SageMaker (training job method)  \n",
    "***Note: Experimental only, since training scripts from kohya have not been published yet  \n",
    "Note: Decoupled training job, training used seperated SageMaker training job***\n",
    "* ml.t3.medium notebook instance is good to run, configure storage with 150GB+, because we need to build large docker images for training job.\n",
    "* Scripts and codes based on [kohya-ss/sd-scripts.](https://github.com/kohya-ss/sd-scripts/tree/sd3)\n",
    "* Training images are from [here](https://github.com/shirayu/example_lora_training)  \n",
    "* We used the trigger word \"wta\"(see in images' caption) for Lora training here, you can change or remove it  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0013ee3b-6a7f-4625-a110-4f122e698925",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Download training dataset and Flux model files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4408032-5d2f-4bcf-a3b8-15cf07a88249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "flux_lora_training = \"./flux_lora_training\"\n",
    "os.makedirs(flux_lora_training, exist_ok=True)\n",
    "\n",
    "%cd flux_lora_training/\n",
    "\n",
    "train_image_dir = \"./images\"\n",
    "docker_file_dir = \"./dockerfile\"\n",
    "os.makedirs(train_image_dir, exist_ok=True)\n",
    "os.makedirs(docker_file_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9335ffaa-51d6-4c16-a85d-1617a285cda3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -P $train_image_dir https://huggingface.co/datasets/terrificdm/wikipe-tan/resolve/main/dataset.zip\n",
    "!unzip $train_image_dir/dataset.zip -d $train_image_dir && rm $train_image_dir/dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3741fbc-2b49-462a-b672-6bd5926c011a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "metadata_file = os.path.join(train_image_dir, 'metadata.jsonl')\n",
    "with open(metadata_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        filename = data['file_name'].split('.')[0]\n",
    "        text = data['text']\n",
    "        output_file = os.path.join(train_image_dir, f'{filename}.txt')\n",
    "        with open(output_file, 'w', encoding='utf-8') as txt_file:\n",
    "            txt_file.write(text)\n",
    "os.remove(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c21fbc-8db1-471a-a89f-1cd720add707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ac1186-fad3-4c45-ad6e-a4b543e6a349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, hf_hub_download\n",
    "\n",
    "# You need to replace below with your own. \n",
    "access_token = \"YOUR_ACCESS_TOKEN_HERE\"\n",
    "login(access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c77cb4-f3cd-4acd-906f-a04c5d586080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = \"./models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "model_vae_repo_id = \"black-forest-labs/FLUX.1-dev\"\n",
    "model_vae_files = [\"flux1-dev.safetensors\", \"ae.safetensors\"]\n",
    "text_encoders_repo_id = \"comfyanonymous/flux_text_encoders\"\n",
    "text_encoders_files = [\"clip_l.safetensors\", \"t5xxl_fp16.safetensors\"]\n",
    "\n",
    "for file in model_vae_files:\n",
    "    hf_hub_download(model_vae_repo_id, local_dir=model_dir, filename=file)\n",
    "for file in text_encoders_files:\n",
    "    hf_hub_download(text_encoders_repo_id, local_dir=model_dir, filename=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74cd90-9ef6-45a6-a302-f4acdaeaf9a6",
   "metadata": {},
   "source": [
    "## 2. Prepare training config files and Dockerfile(docker image for training job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eeb11e-2e1e-4224-a624-7d7ab474fe34",
   "metadata": {},
   "source": [
    "***Refer \"dataset-example.toml\" to configure your own .toml file***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a340910-3cfb-471a-977f-9e71201bae8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./images/dataset.toml\n",
    "[general]\n",
    "enable_bucket = true\n",
    "caption_extension = '.txt'\n",
    "keep_tokens = 0\n",
    "\n",
    "[[datasets]]\n",
    "resolution = 1024\n",
    "# min_bucket_reso = 640\n",
    "# max_bucket_reso = 1536\n",
    "bucket_reso_steps = 32\n",
    "batch_size = 2\n",
    "\n",
    "[[datasets.subsets]]\n",
    "image_dir = '/opt/ml/input/data/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f96139-0e61-4000-a16a-b5ce0fde6e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./images/sample_prompt.toml\n",
    "[prompt]\n",
    "sample_steps = 20\n",
    "width = 1024\n",
    "height = 1024\n",
    "\n",
    "[[prompt.subset]]\n",
    "prompt = \"wta, 1girl, looking at viewer, blue hair, short twintails, hair ornament, blue eyes, blush, smile, open mouth, shirt, skirt, kneehighs, brown footwear, standing, solo\"\n",
    "seed = 1000\n",
    "[[prompt.subset]]\n",
    "prompt = \"wta, 1girl, looking at viewer, blue hair, short twintails, hair ornament, blue eyes, blush, smile, open mouth, shirt, skirt, kneehighs, brown footwear, standing, solo\"\n",
    "seed = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c65b11-0fdf-4768-9096-e934f022c153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./dockerfile/Dockerfile\n",
    "FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:2.3.0-gpu-py311-cu121-ubuntu20.04-sagemaker\n",
    "\n",
    "ENV PATH=\"/opt/ml/code:${PATH}\"\n",
    "ENV SAGEMAKER_SUBMIT_DIRECTORY /opt/ml/code\n",
    "ENV DEBIAN_FRONTEND noninteractive\n",
    "\n",
    "RUN git clone -b sd3 https://github.com/kohya-ss/sd-scripts /opt/ml/code\n",
    "\n",
    "WORKDIR /opt/ml/code\n",
    "\n",
    "RUN mv flux_train_network.py flux_train_network && \\\n",
    "    sed -i 's/-e \\./\\./g' requirements.txt && \\\n",
    "    pip3 install torch==2.4.0 torchvision==0.19.0 --index-url https://download.pytorch.org/whl/cu124 && \\\n",
    "    pip install -r requirements.txt && \\\n",
    "    pip install wandb && \\\n",
    "    pip uninstall transformer-engine -y # Solve error of \"transformer_engine_extensions.cpython-311-x86_64-linux-gnu.so: undefined symbol\"\n",
    "\n",
    "# RUN mkdir -p images/\n",
    "\n",
    "# COPY ./images/* ./images/\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "ENV SAGEMAKER_PROGRAM accelerate.commands.launch --mixed_precision bf16 --num_cpu_threads_per_process 1 flux_train_network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce73c2-4600-4ace-96b6-2b0c34798ed5",
   "metadata": {},
   "source": [
    "## 3. Change default docker-root-dir of SageMaker notebook\n",
    "***Default docker-root-dir of SageMaker notebook has limited space, which is not big enough for building large images***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025960e-8ddc-4f97-9e64-db3cf95b28c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('sudo service docker stop')\n",
    "\n",
    "docker_dir = \"/home/ec2-user/SageMaker/docker\"\n",
    "if not os.path.isdir(docker_dir):\n",
    "    os.system(f'sudo mv /var/lib/docker {docker_dir}')\n",
    "\n",
    "os.system(f'sudo ln -s {docker_dir} /var/lib/docker')\n",
    "\n",
    "os.system('sudo service docker start')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469005ba-e788-425b-aadb-c729e576beb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Build docker image and push to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2244ef-74e1-438d-a176-e48015530eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify an algorithm name\n",
    "algorithm_name=flux-lora-taining-job\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "base_image_repo=\"763104351884.dkr.ecr.${region}.amazonaws.com\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${base_image_repo}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} ./dockerfile\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4430a-6714-409c-bbef-f28ad569f1ae",
   "metadata": {},
   "source": [
    "## 5. Train models with SageMaker training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7bee6-59b0-4170-a3aa-7823a8fa25af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region_name = boto3.session.Session().region_name\n",
    "images_s3uri = 's3://{0}/flux-lora-train/dataset/'.format(bucket)\n",
    "models_s3uri = 's3://{0}/flux-lora-train/models/'.format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef957f93-c7d7-4c39-b82c-597574b3cf7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy training dataset to S3 bucket\n",
    "\n",
    "!aws s3 cp images $images_s3uri --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b323a4e2-fdd7-4909-a97f-1a2a714f3000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy flux model files to S3 bucket\n",
    "\n",
    "!aws s3 cp models $models_s3uri --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925ec1f",
   "metadata": {},
   "source": [
    "***You need to provide your own \"wandb_api_key\" for below scripts***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211af39-31e9-40b9-8d77-51fdaaddedc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    for (k, v) in hyperparameters.items():\n",
    "        print(k, v)\n",
    "    return {k: json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "docker_image_uri = '{0}.dkr.ecr.{1}.amazonaws.com/flux-lora-taining-job'.format(account_id, region_name)\n",
    "instance_type = 'ml.g5.4xlarge'\n",
    "\n",
    "lora_name = \"flux_lora_wta\"\n",
    "output_dir=\"/opt/ml/model/\"\n",
    "wandb_api_key = \"b005e93d3edff303e85dfd44d72a3a5f69fdd853c7\" # Provide your wandb key\n",
    "\n",
    "environment = {'LD_LIBRARY_PATH': \"${LD_LIBRARY_PATH}:/opt/conda/lib/python3.11/site-packages/nvidia/nvjitlink/lib/\"}\n",
    "\n",
    "hyperparameters = {\n",
    "                    'pretrained_model_name_or_path': '/opt/ml/input/data/models/flux1-dev.safetensors',\n",
    "                    'clip_l': '/opt/ml/input/data/models/clip_l.safetensors',\n",
    "                    't5xxl': '/opt/ml/input/data/models/t5xxl_fp16.safetensors',\n",
    "                    'ae': '/opt/ml/input/data/models/ae.safetensors',\n",
    "                    'save_model_as': 'safetensors',\n",
    "                    'sdpa': '',\n",
    "                    'persistent_data_loader_workers': '',\n",
    "                    'max_data_loader_n_workers': 2,\n",
    "                    'gradient_checkpointing': '',\n",
    "                    'mixed_precision': 'bf16',\n",
    "                    'save_precision': 'bf16',\n",
    "                    'full_bf16': '',\n",
    "                    'network_module': 'networks.lora_flux',\n",
    "                    'network_dim': 64,\n",
    "                    'network_alpha': 32,\n",
    "                    'lr_scheduler': 'cosine_with_restarts',\n",
    "                    'lr_scheduler_num_cycles': 1,\n",
    "                    'optimizer_type': 'prodigy',\n",
    "                    'optimizer_args': 'safeguard_warmup=True',\n",
    "                    'learning_rate': 1.0,\n",
    "                    'cache_latents_to_disk': '',\n",
    "                    'cache_text_encoder_outputs_to_disk': '',\n",
    "                    'fp8_base': '',\n",
    "                    'highvram': '',\n",
    "                    'max_train_steps': 540,\n",
    "                    'save_every_n_steps': 120,\n",
    "                    'dataset_config': '/opt/ml/input/data/images/dataset.toml',\n",
    "                    'output_dir': output_dir,\n",
    "                    'output_name': lora_name,\n",
    "                    'timestep_sampling': 'shift',\n",
    "                    'discrete_flow_shift': 3.1582,\n",
    "                    'model_prediction_type': 'raw',\n",
    "                    'guidance_scale': 1,\n",
    "                    't5xxl_max_token_length': 512,\n",
    "                    'sample_every_n_steps': 120,\n",
    "                    'sample_prompts': '/opt/ml/input/data/images/sample_prompt.toml',\n",
    "                    'sample_sampler': 'euler_a',\n",
    "                    'logging_dir': '/opt/ml/code/logs',\n",
    "                    'log_with': 'all',\n",
    "                    'log_tracker_name': lora_name,\n",
    "                    'log_config':'',\n",
    "                    'wandb_api_key': wandb_api_key\n",
    "}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5992287-7d58-4cf5-975f-4f1c0dbd9034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "inputs = {\n",
    "    'images': images_s3uri,\n",
    "    'models': models_s3uri\n",
    "}\n",
    "\n",
    "estimator = Estimator(\n",
    "    role = role,\n",
    "    instance_count=1,\n",
    "    instance_type = instance_type,\n",
    "    image_uri = docker_image_uri,\n",
    "    hyperparameters = hyperparameters,\n",
    "    environment=environment,\n",
    "    disable_output_compression = True\n",
    ")\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "854b2b7d-157e-4b5d-a592-7264b564663e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model artifact saved at: \n",
      "s3://sagemaker-us-east-1-091166060467/flux-lora-taining-job-2024-09-01-00-15-09-583/output/model/\n",
      "\n",
      "                           PRE sample/\n",
      "2024-09-01 02:12:07  634012952 flux_lora_wta-step00000120.safetensors\n",
      "2024-09-01 02:12:14  634012952 flux_lora_wta-step00000240.safetensors\n",
      "2024-09-01 02:12:11  634012952 flux_lora_wta-step00000360.safetensors\n",
      "2024-09-01 02:12:17  634012952 flux_lora_wta-step00000480.safetensors\n",
      "2024-09-01 02:12:19  634012952 flux_lora_wta.safetensors\n"
     ]
    }
   ],
   "source": [
    "model_data = estimator.model_data\n",
    "model_s3_path = model_data['S3DataSource']['S3Uri']\n",
    "print(\"Model artifact saved at:\", \"\\n\"+model_s3_path+\"\\n\")\n",
    "!aws s3 ls {model_s3_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ace31e6-c736-4f47-bf7c-f0ebc9988317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lora weight is saved at: \n",
      "s3://sagemaker-us-east-1-091166060467/flux-lora-taining-job-2024-09-01-00-15-09-583/output/model/flux_lora_wta.safetensors\n"
     ]
    }
   ],
   "source": [
    "# You can change the applied lora weight by changing lora weight name\n",
    "\n",
    "lora_s3_path = model_s3_path + 'flux_lora_wta.safetensors'\n",
    "print (\"Lora weight is saved at:\", \"\\n\"+lora_s3_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
